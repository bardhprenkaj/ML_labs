{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5AYt3Cn35zA"
      },
      "source": [
        "**Challenge: Implement a Multiclass Classification Neural network using PyTorch**\n",
        "\n",
        "Objective:\n",
        "Build a neural network using PyTorch to predict handwritten digits of MNIST.\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. **Data Preparation**: Load the MNIST dataset using ```torchvision.datasets.MNIST```. Standardize/normalize the features. Split the dataset into training and testing sets using, for example, ```sklearn.model_selection.train_test_split()```. **Bonus scores**: *use PyTorch's built-* ```DataLoader``` *to split the dataset*.\n",
        "\n",
        "2. **Neural network Architecture**: Define a simple feedforward neural network using PyTorch's ```nn.Module```. Design the input layer to match the number of features in the MNIST dataset and the output layer to have as many neurons as there are classes (10). You can experiment with the number of hidden layers and neurons to optimize the performance. **Bonus scores**: *Make your architecture flexibile to have as many hidden layers as the user wants, and use hyperparameter optimization to select the best number of hidden layeres.*\n",
        "\n",
        "3. **Loss Function and Optimizer**: Choose an appropriate loss function for multiclass classification. Select an optimizer, like SGD (Stochastic Gradient Descent) or Adam.\n",
        "\n",
        "4. **Training**: Write a training loop to iterate over the dataset.\n",
        "Forward pass the input through the network, calculate the loss, and perform backpropagation. Update the weights of the network using the chosen optimizer.\n",
        "\n",
        "5. **Testing**: Evaluate the trained model on the test set. Calculate the accuracy of the model.\n",
        "\n",
        "6. **Optimization**: Experiment with hyperparameters (learning rate, number of epochs, etc.) to optimize the model's performance. Consider adjusting the neural network architecture for better results. **Notice that you can't use the optimization algorithms from scikit-learn that we saw in lab1: e.g.,** ```GridSearchCV```.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDuvQmiUrVXp"
      },
      "source": [
        "# Intro\n",
        "\n",
        "This is a brief guide and summary of this notebook.\n",
        "\n",
        "In the imports and setup chapter we do all our imports and preprocess our data. In this notebook skorch is used, uncomment the pip command to use it on colab.\n",
        "\n",
        "In the NN chapter there's an implementation of a simple, not configurable feed forward network. The subdivision is kinda straightforward.\n",
        "\n",
        "In the Custom NN chapter there's an implementation of a configurable ffn. The parameter 'layers' is a list of the dimension of the input of each layer, the parameter 'inputSize' is the dimension of the input layer and the parameter 'hiddenDefault' is used only in case there aren't any hidden layout and it determinate the size of the input of the output layer.\n",
        "Between each layer an activation layer is inserted automatically.\n",
        "So if we have input size 28 * 28, layer=[200,100] our structure will be: [ ('layer1',(28*28,200)), ('act1',fn), ('layer2',(200,100)), ('act2',fn), ('layer3',(100,10))]\n",
        "\n",
        "In the last chapter we have a Skorch implementation. Skorch is a sklearn wrapper used for pytorch. It's mere purpose is to create an interface to use sklearn methods on pytorch modules. I used it to been able to use sklearn GridSearchCV in order to fine tune the hyperparameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0ycuQ8nrVXr"
      },
      "source": [
        "# Imports and setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZozXPYDrVXt"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9mJfwmBrVXv",
        "outputId": "4adbd5f2-bff1-4496-e67f-8fb5a8c3db38"
      },
      "outputs": [],
      "source": [
        "#!pip install skorch\n",
        "\n",
        "import torchvision.datasets.mnist as mnist\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17EUKd4drVXx"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.is_available()\n",
        "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "#The data is already divided into train and test by the authors of the dataset, so I'm not sure about the request to divide it with train_test_split.\n",
        "dataset = mnist.MNIST(root='./data', download=True, train=True, transform=transform)\n",
        "testset = mnist.MNIST(root='./data', download=True, train=False, transform=transform)\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(len(dataset))\n",
        "print(len(testset))\n",
        "print(len(trainloader))\n",
        "print(len(testloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj9U0ANjrVXz"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrG1C-_5rVX1"
      },
      "source": [
        "## Init of NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6NXofXRwrVX2"
      },
      "outputs": [],
      "source": [
        "class myNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(myNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 200)\n",
        "        self.fc2 = nn.Linear(200, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "\n",
        "ffn = myNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(ffn.parameters(), lr=0.001, momentum=0.4)\n",
        "optimizer = optim.Adam(ffn.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LVPVvEvrVX3"
      },
      "source": [
        "## Training phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5XLynrxJ33v6",
        "outputId": "cf1b6749-cf0d-4fa4-d485-2c27a49cb916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2000] loss: 0.48010443090088667\n",
            "[1, 4000] loss: 0.27761990653903923\n",
            "[1, 6000] loss: 0.21578022703243185\n",
            "[2, 2000] loss: 0.1763130079927796\n",
            "[2, 4000] loss: 0.16941093571758392\n",
            "[2, 6000] loss: 0.16122472617687528\n",
            "[3, 2000] loss: 0.12922619332366958\n",
            "[3, 4000] loss: 0.13863731349368982\n",
            "[3, 6000] loss: 0.1432750749830593\n",
            "[4, 2000] loss: 0.1182959944759441\n",
            "[4, 4000] loss: 0.117022002852058\n",
            "[4, 6000] loss: 0.12597192210779212\n",
            "[5, 2000] loss: 0.10888234706892218\n",
            "[5, 4000] loss: 0.10499607920552625\n",
            "[5, 6000] loss: 0.10969750836172171\n",
            "[6, 2000] loss: 0.09327202055015642\n",
            "[6, 4000] loss: 0.10350502500523907\n",
            "[6, 6000] loss: 0.10020245129187878\n",
            "[7, 2000] loss: 0.09295159343919096\n",
            "[7, 4000] loss: 0.09545812236633153\n",
            "[7, 6000] loss: 0.09950098262791073\n",
            "[8, 2000] loss: 0.08312258570839821\n",
            "[8, 4000] loss: 0.08768206606775823\n",
            "[8, 6000] loss: 0.09165356756828837\n",
            "[9, 2000] loss: 0.07648560665158646\n",
            "[9, 4000] loss: 0.08711659955348551\n",
            "[9, 6000] loss: 0.08280397975034108\n",
            "[10, 2000] loss: 0.07326814749243792\n",
            "[10, 4000] loss: 0.07994050240163107\n",
            "[10, 6000] loss: 0.08105545770693555\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = ffn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 2000 == 1999:\n",
        "            print(f'[{epoch+1}, {i+1}] loss: {running_loss/2000}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy_of2SPrVX5"
      },
      "source": [
        "## Train phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hnJI9UayrVX6",
        "outputId": "b002cffd-b42b-4b65-e959-5e4824e1f32c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.07%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = ffn(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted==labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100*correct/total}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq5uEO5ErVX7"
      },
      "source": [
        "# Custom NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "SYw01x-urVX7"
      },
      "outputs": [],
      "source": [
        "\n",
        "class myNN(nn.Module):\n",
        "    def __init__(self, hiddenDefault=100,inputSize=28*28,layers=[],hiddenFun=nn.ReLU(),firstFun=nn.ReLU(),dropout=True,dropVal=0.3):\n",
        "        super(myNN, self).__init__()\n",
        "\n",
        "        #initialize hidden layers, we add ReLU after each layer except the last one.\n",
        "        hidden = nn.Sequential()\n",
        "        for i in range(len(layers) - 1):\n",
        "            hidden.add_module(f\"Linear{i}\", nn.Linear(layers[i], layers[i + 1]))\n",
        "            if i < len(layers) - 2:\n",
        "                hidden.add_module(f\"ReLU{i}\", hiddenFun)\n",
        "                if dropout:\n",
        "                  hidden.add_module(f'Dropout{i}',nn.Dropout(dropVal))\n",
        "\n",
        "        #we prepare the connection between the fc1, hidden and fc2 layers.\n",
        "        if(len(layers)>0):\n",
        "            hiddenInput=layers[0]\n",
        "            hiddenOutput=layers[-1]\n",
        "        else:\n",
        "            hiddenInput=hiddenDefault\n",
        "            hiddenOutput=hiddenDefault\n",
        "\n",
        "\n",
        "        self.inputSize=inputSize\n",
        "        self.hiddenInput=hiddenInput\n",
        "        self.hiddenOutput=hiddenOutput\n",
        "        self.firstFun=firstFun\n",
        "\n",
        "        self.fc1 = nn.Linear(inputSize, hiddenInput)\n",
        "        self.hidden=hidden\n",
        "        self.fc2 = nn.Linear(hiddenOutput, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(-1, self.inputSize)\n",
        "        x = self.fc1(x)\n",
        "        x = self.firstFun(x)\n",
        "        x = self.hidden(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "ffn = myNN(layers=[70],dropout=False).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Qxsegs6FrVX8"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(ffn.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jQeftFprVX8"
      },
      "source": [
        "## Training phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IHTz3WqrVX8",
        "outputId": "b76c8fb9-bb1e-4ac8-8038-5bbdd43ea7fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2000] loss: 0.8756500407177955\n",
            "[1, 4000] loss: 0.4193520734682679\n",
            "[1, 6000] loss: 0.36563054214883595\n",
            "[2, 2000] loss: 0.3112572430926375\n",
            "[2, 4000] loss: 0.29173303379537535\n",
            "[2, 6000] loss: 0.27918854940496385\n",
            "[3, 2000] loss: 0.24766510563646443\n",
            "[3, 4000] loss: 0.23948690553428606\n",
            "[3, 6000] loss: 0.23008980083209463\n",
            "[4, 2000] loss: 0.20886862733843736\n",
            "[4, 4000] loss: 0.19785064445238096\n",
            "[4, 6000] loss: 0.20286418897646946\n",
            "[5, 2000] loss: 0.17599192129657604\n",
            "[5, 4000] loss: 0.17986748983117287\n",
            "[5, 6000] loss: 0.16666196359856986\n",
            "[6, 2000] loss: 0.1504832161619561\n",
            "[6, 4000] loss: 0.16270032851863653\n",
            "[6, 6000] loss: 0.15067298324999864\n",
            "[7, 2000] loss: 0.1369216052828124\n",
            "[7, 4000] loss: 0.13601353262510382\n",
            "[7, 6000] loss: 0.13292419160914143\n",
            "[8, 2000] loss: 0.12473735597921769\n",
            "[8, 4000] loss: 0.12166116120404331\n",
            "[8, 6000] loss: 0.1243082568491227\n",
            "[9, 2000] loss: 0.11848127367842244\n",
            "[9, 4000] loss: 0.11910722489099135\n",
            "[9, 6000] loss: 0.10481672462739516\n",
            "[10, 2000] loss: 0.10361941423435929\n",
            "[10, 4000] loss: 0.0995474794920301\n",
            "[10, 6000] loss: 0.10902333064396226\n",
            "[11, 2000] loss: 0.09447293774667195\n",
            "[11, 4000] loss: 0.09927638147637481\n",
            "[11, 6000] loss: 0.09620522583680577\n",
            "[12, 2000] loss: 0.08654027962867986\n",
            "[12, 4000] loss: 0.09236937448158278\n",
            "[12, 6000] loss: 0.08891354964888888\n",
            "[13, 2000] loss: 0.08487449585454306\n",
            "[13, 4000] loss: 0.08415030772198225\n",
            "[13, 6000] loss: 0.08500341691501671\n",
            "[14, 2000] loss: 0.07748983153120208\n",
            "[14, 4000] loss: 0.0815518697432999\n",
            "[14, 6000] loss: 0.08198512485846005\n",
            "[15, 2000] loss: 0.07006814025088534\n",
            "[15, 4000] loss: 0.07438831861245854\n",
            "[15, 6000] loss: 0.07578372137074621\n",
            "[16, 2000] loss: 0.07019907254264399\n",
            "[16, 4000] loss: 0.07661483966691594\n",
            "[16, 6000] loss: 0.06734691947387546\n",
            "[17, 2000] loss: 0.06655837987857739\n",
            "[17, 4000] loss: 0.0683286450817468\n",
            "[17, 6000] loss: 0.06565462631569244\n",
            "[18, 2000] loss: 0.06326565567227954\n",
            "[18, 4000] loss: 0.06511139263473524\n",
            "[18, 6000] loss: 0.0631361036491835\n",
            "[19, 2000] loss: 0.05866618902904156\n",
            "[19, 4000] loss: 0.06261849934729252\n",
            "[19, 6000] loss: 0.060225206932438595\n",
            "[20, 2000] loss: 0.0552612193419518\n",
            "[20, 4000] loss: 0.058861205399847676\n",
            "[20, 6000] loss: 0.06109733746204438\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = ffn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 2000 == 1999:\n",
        "            print(f'[{epoch+1}, {i+1}] loss: {running_loss/2000}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "273hT871rVX9"
      },
      "source": [
        "## Test phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d3rXup4rVX9",
        "outputId": "d1e8e4ac-bfb9-4361-919d-9f08e6b462ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.36%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = ffn(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted==labels).sum().item()\n",
        "\n",
        "\n",
        "defaultAccuracy=100*correct/total\n",
        "print(f'Accuracy of the network on the 10000 test images: {defaultAccuracy}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLL-rYtHrVX_"
      },
      "source": [
        "# Skorch implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6TBBvcDXrVYB"
      },
      "outputs": [],
      "source": [
        "# create the skorch wrapper\n",
        "model = NeuralNetClassifier(\n",
        "    module=myNN(layers=[500,200,100]),  # define the module here\n",
        "    criterion=nn.CrossEntropyLoss,\n",
        "    optimizer=optim.Adam,\n",
        "    max_epochs=40,\n",
        "    lr=0.00007,\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ouCDCo9XrVYD",
        "outputId": "4325c051-77c1-4a36-a072-cb0a0db69a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: torch.Size([60000, 784])\n",
            "y shape: torch.Size([60000])\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6145\u001b[0m       \u001b[32m0.8868\u001b[0m        \u001b[35m0.3797\u001b[0m  5.2412\n",
            "      2        \u001b[36m0.5014\u001b[0m       \u001b[32m0.9226\u001b[0m        \u001b[35m0.2674\u001b[0m  5.1238\n",
            "      3        \u001b[36m0.3526\u001b[0m       \u001b[32m0.9362\u001b[0m        \u001b[35m0.2176\u001b[0m  5.1285\n",
            "      4        \u001b[36m0.2781\u001b[0m       \u001b[32m0.9453\u001b[0m        \u001b[35m0.1860\u001b[0m  5.0940\n",
            "      5        \u001b[36m0.2284\u001b[0m       \u001b[32m0.9496\u001b[0m        \u001b[35m0.1663\u001b[0m  5.0871\n",
            "      6        \u001b[36m0.1956\u001b[0m       \u001b[32m0.9534\u001b[0m        \u001b[35m0.1506\u001b[0m  5.1562\n",
            "      7        \u001b[36m0.1691\u001b[0m       \u001b[32m0.9569\u001b[0m        \u001b[35m0.1395\u001b[0m  5.1499\n",
            "      8        \u001b[36m0.1469\u001b[0m       \u001b[32m0.9601\u001b[0m        \u001b[35m0.1299\u001b[0m  5.0865\n",
            "      9        \u001b[36m0.1294\u001b[0m       \u001b[32m0.9623\u001b[0m        \u001b[35m0.1221\u001b[0m  5.0821\n",
            "     10        \u001b[36m0.1130\u001b[0m       \u001b[32m0.9643\u001b[0m        \u001b[35m0.1157\u001b[0m  5.1011\n",
            "     11        \u001b[36m0.1021\u001b[0m       \u001b[32m0.9657\u001b[0m        \u001b[35m0.1103\u001b[0m  5.1332\n",
            "     12        \u001b[36m0.0917\u001b[0m       \u001b[32m0.9673\u001b[0m        \u001b[35m0.1062\u001b[0m  5.0699\n",
            "     13        \u001b[36m0.0817\u001b[0m       \u001b[32m0.9689\u001b[0m        \u001b[35m0.1010\u001b[0m  5.0963\n",
            "     14        \u001b[36m0.0714\u001b[0m       \u001b[32m0.9702\u001b[0m        \u001b[35m0.0979\u001b[0m  5.1000\n",
            "     15        \u001b[36m0.0654\u001b[0m       \u001b[32m0.9718\u001b[0m        \u001b[35m0.0942\u001b[0m  5.1191\n",
            "     16        \u001b[36m0.0582\u001b[0m       \u001b[32m0.9723\u001b[0m        \u001b[35m0.0929\u001b[0m  5.0691\n",
            "     17        \u001b[36m0.0530\u001b[0m       \u001b[32m0.9724\u001b[0m        \u001b[35m0.0905\u001b[0m  5.0811\n",
            "     18        \u001b[36m0.0486\u001b[0m       \u001b[32m0.9732\u001b[0m        \u001b[35m0.0881\u001b[0m  5.1198\n",
            "     19        \u001b[36m0.0431\u001b[0m       \u001b[32m0.9752\u001b[0m        \u001b[35m0.0865\u001b[0m  5.2011\n",
            "     20        \u001b[36m0.0398\u001b[0m       0.9751        \u001b[35m0.0853\u001b[0m  5.0621\n",
            "     21        \u001b[36m0.0359\u001b[0m       0.9751        \u001b[35m0.0835\u001b[0m  5.1362\n",
            "     22        \u001b[36m0.0329\u001b[0m       \u001b[32m0.9753\u001b[0m        0.0837  5.0539\n",
            "     23        \u001b[36m0.0288\u001b[0m       \u001b[32m0.9762\u001b[0m        \u001b[35m0.0830\u001b[0m  5.0978\n",
            "     24        \u001b[36m0.0255\u001b[0m       0.9759        \u001b[35m0.0818\u001b[0m  5.1047\n",
            "     25        \u001b[36m0.0230\u001b[0m       \u001b[32m0.9770\u001b[0m        \u001b[35m0.0818\u001b[0m  5.0481\n",
            "     26        \u001b[36m0.0222\u001b[0m       0.9770        0.0824  5.0931\n",
            "     27        \u001b[36m0.0204\u001b[0m       \u001b[32m0.9775\u001b[0m        \u001b[35m0.0807\u001b[0m  5.0881\n",
            "     28        \u001b[36m0.0182\u001b[0m       0.9773        0.0833  5.0823\n",
            "     29        \u001b[36m0.0174\u001b[0m       \u001b[32m0.9780\u001b[0m        \u001b[35m0.0804\u001b[0m  5.0821\n",
            "     30        \u001b[36m0.0158\u001b[0m       \u001b[32m0.9782\u001b[0m        0.0810  5.0921\n",
            "     31        \u001b[36m0.0142\u001b[0m       0.9775        0.0815  5.1972\n",
            "     32        \u001b[36m0.0131\u001b[0m       \u001b[32m0.9794\u001b[0m        0.0804  5.0739\n",
            "     33        \u001b[36m0.0122\u001b[0m       0.9786        \u001b[35m0.0799\u001b[0m  5.0981\n",
            "     34        \u001b[36m0.0117\u001b[0m       0.9791        0.0801  5.0591\n",
            "     35        \u001b[36m0.0104\u001b[0m       0.9782        0.0837  5.0988\n",
            "     36        \u001b[36m0.0103\u001b[0m       \u001b[32m0.9797\u001b[0m        \u001b[35m0.0786\u001b[0m  5.0595\n",
            "     37        \u001b[36m0.0082\u001b[0m       0.9794        0.0809  5.0623\n",
            "     38        0.0083       0.9796        0.0798  5.1762\n",
            "     39        \u001b[36m0.0079\u001b[0m       0.9797        0.0829  5.1502\n",
            "     40        \u001b[36m0.0077\u001b[0m       0.9795        0.0819  5.1159\n",
            "     41        \u001b[36m0.0072\u001b[0m       0.9788        0.0837  5.1014\n",
            "     42        \u001b[36m0.0061\u001b[0m       0.9789        0.0849  5.1128\n",
            "     43        \u001b[36m0.0052\u001b[0m       0.9778        0.0865  5.0211\n",
            "     44        0.0062       \u001b[32m0.9801\u001b[0m        0.0844  4.9921\n",
            "     45        0.0059       0.9775        0.0883  5.0881\n",
            "     46        \u001b[36m0.0050\u001b[0m       \u001b[32m0.9803\u001b[0m        0.0806  5.0296\n",
            "     47        \u001b[36m0.0043\u001b[0m       0.9794        0.0845  5.1463\n",
            "     48        0.0047       0.9794        0.0852  4.9831\n",
            "     49        0.0043       0.9801        0.0846  5.1021\n",
            "     50        \u001b[36m0.0042\u001b[0m       0.9802        0.0838  5.0348\n",
            "     51        \u001b[36m0.0038\u001b[0m       0.9796        0.0852  5.0245\n",
            "     52        0.0039       0.9802        0.0832  5.0677\n",
            "     53        0.0046       0.9799        0.0852  5.0869\n",
            "     54        0.0039       0.9802        0.0836  5.0890\n",
            "     55        \u001b[36m0.0027\u001b[0m       \u001b[32m0.9809\u001b[0m        0.0852  5.1442\n",
            "     56        0.0030       0.9802        0.0873  5.0191\n",
            "     57        \u001b[36m0.0027\u001b[0m       \u001b[32m0.9812\u001b[0m        0.0861  5.0471\n",
            "     58        0.0031       0.9804        0.0872  4.9559\n",
            "     59        0.0030       0.9809        0.0836  5.0035\n",
            "     60        \u001b[36m0.0026\u001b[0m       0.9806        0.0868  4.7531\n",
            "     61        \u001b[36m0.0024\u001b[0m       0.9802        0.0886  4.7453\n",
            "     62        \u001b[36m0.0022\u001b[0m       0.9800        0.0864  4.7646\n",
            "     63        0.0024       \u001b[32m0.9818\u001b[0m        0.0870  4.7850\n",
            "     64        \u001b[36m0.0020\u001b[0m       0.9810        0.0909  4.8381\n",
            "     65        0.0023       0.9802        0.0871  4.8362\n",
            "     66        0.0021       0.9806        0.0859  4.8361\n",
            "     67        0.0020       0.9810        0.0877  4.8721\n",
            "     68        \u001b[36m0.0018\u001b[0m       0.9807        0.0906  5.0024\n",
            "     69        0.0020       0.9806        0.0902  5.0138\n",
            "     70        0.0022       0.9810        0.0883  5.2713\n",
            "     71        \u001b[36m0.0018\u001b[0m       0.9805        0.0902  5.2740\n",
            "     72        \u001b[36m0.0015\u001b[0m       0.9814        0.0909  5.2102\n",
            "     73        0.0016       0.9809        0.0907  5.2502\n",
            "     74        0.0016       0.9808        0.0907  5.2898\n",
            "     75        0.0021       0.9803        0.0932  5.2913\n",
            "     76        0.0016       0.9804        0.0911  5.2997\n",
            "     77        \u001b[36m0.0011\u001b[0m       0.9811        0.0935  5.3262\n",
            "     78        0.0012       0.9799        0.0977  5.3042\n",
            "     79        0.0015       0.9803        0.0931  5.2802\n",
            "     80        0.0012       0.9808        0.0913  5.2766\n",
            "     81        0.0011       0.9802        0.0954  5.2265\n",
            "     82        0.0012       0.9804        0.0956  5.2582\n",
            "     83        0.0013       0.9805        0.0977  5.3081\n",
            "     84        0.0012       0.9806        0.0992  5.2880\n",
            "     85        0.0015       0.9811        0.0949  5.3157\n",
            "     86        0.0016       0.9812        0.0934  5.3139\n",
            "     87        0.0012       0.9807        0.0962  5.3033\n",
            "     88        \u001b[36m0.0010\u001b[0m       0.9812        0.0962  5.2820\n",
            "     89        \u001b[36m0.0009\u001b[0m       0.9817        0.0948  5.2924\n",
            "     90        0.0011       0.9809        0.0995  5.2832\n",
            "     91        0.0013       0.9812        0.0999  5.3392\n",
            "     92        0.0013       0.9813        0.0930  5.3263\n",
            "     93        0.0011       0.9809        0.0982  5.2822\n",
            "     94        0.0014       0.9813        0.0966  5.3012\n",
            "     95        0.0014       0.9806        0.0912  5.2612\n",
            "     96        0.0011       \u001b[32m0.9820\u001b[0m        0.0949  5.3063\n",
            "     97        0.0010       0.9812        0.0986  5.3084\n",
            "     98        \u001b[36m0.0006\u001b[0m       0.9812        0.0982  5.3202\n",
            "     99        0.0006       0.9808        0.0958  5.3182\n",
            "    100        0.0008       0.9808        0.0978  5.2604\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=myNN(\n",
              "    (firstFun): ReLU()\n",
              "    (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
              "    (hidden): Sequential(\n",
              "      (Linear0): Linear(in_features=500, out_features=200, bias=True)\n",
              "      (ReLU0): ReLU()\n",
              "      (Dropout0): Dropout(p=0.3, inplace=False)\n",
              "      (Linear1): Linear(in_features=200, out_features=100, bias=True)\n",
              "    )\n",
              "    (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  ),\n",
              "),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;module__dropVal&#x27;: [0.3],\n",
              "                         &#x27;module__layers&#x27;: [[100], [500], [100, 100],\n",
              "                                            [500, 100], [1000, 500, 100],\n",
              "                                            [1000, 300, 100], [500, 200, 100],\n",
              "                                            [200, 200, 100]]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=myNN(\n",
              "    (firstFun): ReLU()\n",
              "    (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
              "    (hidden): Sequential(\n",
              "      (Linear0): Linear(in_features=500, out_features=200, bias=True)\n",
              "      (ReLU0): ReLU()\n",
              "      (Dropout0): Dropout(p=0.3, inplace=False)\n",
              "      (Linear1): Linear(in_features=200, out_features=100, bias=True)\n",
              "    )\n",
              "    (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  ),\n",
              "),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;module__dropVal&#x27;: [0.3],\n",
              "                         &#x27;module__layers&#x27;: [[100], [500], [100, 100],\n",
              "                                            [500, 100], [1000, 500, 100],\n",
              "                                            [1000, 300, 100], [500, 200, 100],\n",
              "                                            [200, 200, 100]]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=myNN(\n",
              "    (firstFun): ReLU()\n",
              "    (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
              "    (hidden): Sequential(\n",
              "      (Linear0): Linear(in_features=500, out_features=200, bias=True)\n",
              "      (ReLU0): ReLU()\n",
              "      (Dropout0): Dropout(p=0.3, inplace=False)\n",
              "      (Linear1): Linear(in_features=200, out_features=100, bias=True)\n",
              "    )\n",
              "    (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  ),\n",
              ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=myNN(\n",
              "    (firstFun): ReLU()\n",
              "    (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
              "    (hidden): Sequential(\n",
              "      (Linear0): Linear(in_features=500, out_features=200, bias=True)\n",
              "      (ReLU0): ReLU()\n",
              "      (Dropout0): Dropout(p=0.3, inplace=False)\n",
              "      (Linear1): Linear(in_features=200, out_features=100, bias=True)\n",
              "    )\n",
              "    (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  ),\n",
              ")</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
              "  module=myNN(\n",
              "    (firstFun): ReLU()\n",
              "    (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
              "    (hidden): Sequential(\n",
              "      (Linear0): Linear(in_features=500, out_features=200, bias=True)\n",
              "      (ReLU0): ReLU()\n",
              "      (Dropout0): Dropout(p=0.3, inplace=False)\n",
              "      (Linear1): Linear(in_features=200, out_features=100, bias=True)\n",
              "    )\n",
              "    (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  ),\n",
              "),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'module__dropVal': [0.3],\n",
              "                         'module__layers': [[100], [500], [100, 100],\n",
              "                                            [500, 100], [1000, 500, 100],\n",
              "                                            [1000, 300, 100], [500, 200, 100],\n",
              "                                            [200, 200, 100]]},\n",
              "             scoring='accuracy')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'module__layers': [[100],[500],[100,100],[500,100],[1000,500,100],[1000,300,100],[500,200,100],[200,200,100],],\n",
        "    'module__dropVal': [0.3],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
        "\n",
        "X = dataset.data.reshape(-1,28*28).float()\n",
        "y = dataset.targets\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "grid_search.fit(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "JUcgUzcirVYE",
        "outputId": "80ef8e0c-a4a2-49ea-d6e8-4d10924358ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9768333333333332,\n",
              " {'module__dropVal': 0.3, 'module__layers': [1000, 500, 100]})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracyTuned=grid_search.best_score_*100\n",
        "grid_search.best_score_, grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "WGTPSm6IrVYF",
        "outputId": "b31239e0-6877-46fc-d616-2a6fb46bc4e3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "val1=[defaultAccuracy,defaultAccuracy]\n",
        "plt.bar([\"Default\",\"Tuned\"],val1,color='blue')\n",
        "plt.bar([\"Default\",\"Tuned\"],[0,accuracyTuned-defaultAccuracy],bottom=val1,color='lightblue')\n",
        "# Add a dotted line\n",
        "plt.axhline(y=defaultAccuracy, color='red', linestyle='dotted')\n",
        "\n",
        "plt.ylim(defaultAccuracy-(defaultAccuracy/10),accuracyTuned+(accuracyTuned/40))\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
