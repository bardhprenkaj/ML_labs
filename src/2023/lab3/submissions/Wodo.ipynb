{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Challenge: Implement a Multiclass Classification Neural Network using PyTorch**\n",
        "\n",
        "Objective:\n",
        "Build a neural network using PyTorch to predict handwritten digits of MNIST.\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. **Data Preparation**: Load the MNIST dataset using ```torchvision.datasets.MNIST```. Standardize/normalize the features. Split the dataset into training and testing sets using, for example, ```sklearn.model_selection.train_test_split()```. **Bonus scores**: *use PyTorch's built-* ```DataLoader``` *to split the dataset*.\n",
        "\n",
        "2. **Neural Network Architecture**: Define a simple feedforward neural network using PyTorch's ```nn.Module```. Design the input layer to match the number of features in the MNIST dataset and the output layer to have as many neurons as there are classes (10). You can experiment with the number of hidden layers and neurons to optimize the performance. **Bonus scores**: *Make your architecture flexibile to have as many hidden layers as the user wants, and use hyperparameter optimization to select the best number of hidden layeres.*\n",
        "\n",
        "3. **Loss Function and Optimizer**: Choose an appropriate loss function for multiclass classification. Select an optimizer, like SGD (Stochastic Gradient Descent) or Adam.\n",
        "\n",
        "4. **Training**: Write a training loop to iterate over the dataset.\n",
        "Forward pass the input through the network, calculate the loss, and perform backpropagation. Update the weights of the network using the chosen optimizer.\n",
        "\n",
        "5. **Testing**: Evaluate the trained model on the test set. Calculate the accuracy of the model.\n",
        "\n",
        "6. **Optimization**: Experiment with hyperparameters (learning rate, number of epochs, etc.) to optimize the model's performance. Consider adjusting the neural network architecture for better results. **Notice that you can't use the optimization algorithms from scikit-learn that we saw in lab1: e.g.,** ```GridSearchCV```.\n"
      ],
      "metadata": {
        "id": "E5AYt3Cn35zA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## >>STEP 1<<"
      ],
      "metadata": {
        "id": "p-2m0T53qQWL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5XLynrxJ33v6"
      },
      "outputs": [],
      "source": [
        "#Import libraries\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.8,))])"
      ],
      "metadata": {
        "id": "s3lNeMNRp5y6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download= True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download= True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W5q3nT1p724",
        "outputId": "f2d3a8ed-5e32-44b2-f699-e6a23b7978a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 121903602.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 43985364.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 32138983.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2777854.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'train {trainset}')\n",
        "print(f'test {testset}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMVuSJXcp9ik",
        "outputId": "7cc3a0ae-5597-4043-8ff7-8d134501e1b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5,), std=(0.8,))\n",
            "           )\n",
            "test Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5,), std=(0.8,))\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "Xif2S1_ip_Z5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "9sAIrxDvqEhu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# >>STEP 2<<"
      ],
      "metadata": {
        "id": "vvNTcfzhqVVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTConvNet(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    #The first layer must be here\n",
        "\n",
        "    #first layer\n",
        "    self.f1 = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(784, 300)\n",
        "    self.act1 = nn.Sigmoid()\n",
        "\n",
        "    #hidden layer\n",
        "    self.fcX = nn.ModuleList([nn.Linear(300,300) for i in range(hidden_layers)])\n",
        "\n",
        "    self.act2 = nn.Sigmoid()\n",
        "    #last layer\n",
        "    self.flat = nn.Flatten()\n",
        "    self.fc2 = nn.Linear(300, 100)\n",
        "    self.act3 = nn.Sigmoid()\n",
        "    self.fc3 = nn.Linear(100,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    #First Layer\n",
        "    x = self.f1(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.act1(x)\n",
        "\n",
        "    for i, l in enumerate(self.fcX):\n",
        "      x = self.fcX[i // 2](x) + l(x)\n",
        "\n",
        "    x = self.act2(x)\n",
        "    x = self.flat(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.act3(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "c4NSszgrsdd_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#insert the number of hidden layers\n",
        "hidden_layers = 5"
      ],
      "metadata": {
        "id": "2OZl0AF2xQjP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTConvNet(hidden_layers)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImAnevXhxKNu",
        "outputId": "f17155e8-32ec-4c42-d6c9-2d9739bfb6d2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNISTConvNet(\n",
              "  (f1): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
              "  (act1): Sigmoid()\n",
              "  (fcX): ModuleList(\n",
              "    (0-4): 5 x Linear(in_features=300, out_features=300, bias=True)\n",
              "  )\n",
              "  (act2): Sigmoid()\n",
              "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
              "  (act3): Sigmoid()\n",
              "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DuUhz2tSxJ-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTConvNet(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_layers):\n",
        "    super().__init__()\n",
        "\n",
        "#The first layer must be here\n",
        "\n",
        "    self.first = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(784, 300),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    self.list_modules = []\n",
        "    for i in range(hidden_layers):\n",
        "      self.list_modules.append(nn.Sequential(\n",
        "          nn.Linear(300,300),\n",
        "          nn.Sigmoid()\n",
        "      ))\n",
        "\n",
        "    self.last = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(300,100),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(100,10)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.first(x)\n",
        "    for i in range(hidden_layers):\n",
        "      x = self.list_modules[i](x)\n",
        "    x = self.last(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "FQAvmDjBwjEp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTConvNet(hidden_layers)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGmV-K4Ebb9k",
        "outputId": "6ecafed1-230a-48cb-aaca-a689aca31f4d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNISTConvNet(\n",
              "  (first): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
              "    (2): Sigmoid()\n",
              "  )\n",
              "  (last): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=300, out_features=100, bias=True)\n",
              "    (2): Sigmoid()\n",
              "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the use of list for nn.Sequential doesn't put into the model the hidden layers, i will use ModuleList instead. I will leave the output of the created model with nn.Sequential to show the difference."
      ],
      "metadata": {
        "id": "RvznByokvnVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3"
      ],
      "metadata": {
        "id": "Z6BdPbdWlPNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #SGD = Stochastic gradient descent"
      ],
      "metadata": {
        "id": "vL4QbWOAq_R_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4 & STEP 5"
      ],
      "metadata": {
        "id": "gw4MQcH9r5fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10"
      ],
      "metadata": {
        "id": "R2w0oOPWsQPb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "  losses = []\n",
        "#training\n",
        "  for inputs, labels in trainloader:\n",
        "\n",
        "    y_pred = model(inputs)\n",
        "    loss = loss_fn(y_pred, labels)\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'Epoch {epoch + 1} --> loss = {np.mean(losses)}')\n",
        "\n",
        "  acc = 0\n",
        "  count = 0\n",
        "  for inputs, labels in testloader:\n",
        "\n",
        "    y_pred = model(inputs)\n",
        "\n",
        "    acc += (torch.argmax(y_pred,1) == labels).float().sum()\n",
        "    count += len(labels)\n",
        "\n",
        "  acc /= count\n",
        "\n",
        "  print(f'Epoch {epoch + 1} --> model accuracy = {acc * 100}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8RgBJbQr9Hu",
        "outputId": "f654450e-c56d-4218-f9c5-c2628c495c9c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 --> loss = 2.303351174799601\n",
            "Epoch 1 --> model accuracy = 10.279999732971191\n",
            "Epoch 2 --> loss = 2.3019251496632895\n",
            "Epoch 2 --> model accuracy = 11.350000381469727\n",
            "Epoch 3 --> loss = 2.300648187637329\n",
            "Epoch 3 --> model accuracy = 20.989999771118164\n",
            "Epoch 4 --> loss = 2.2936515225728353\n",
            "Epoch 4 --> model accuracy = 21.81999969482422\n",
            "Epoch 5 --> loss = 2.000452421506246\n",
            "Epoch 5 --> model accuracy = 29.660001754760742\n",
            "Epoch 6 --> loss = 1.593509429359436\n",
            "Epoch 6 --> model accuracy = 49.209999084472656\n",
            "Epoch 7 --> loss = 1.174327398777008\n",
            "Epoch 7 --> model accuracy = 61.43000030517578\n",
            "Epoch 8 --> loss = 0.9982069915771484\n",
            "Epoch 8 --> model accuracy = 71.17000579833984\n",
            "Epoch 9 --> loss = 0.8350652021884918\n",
            "Epoch 9 --> model accuracy = 76.9800033569336\n",
            "Epoch 10 --> loss = 0.7072107039928436\n",
            "Epoch 10 --> model accuracy = 81.20999908447266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 6"
      ],
      "metadata": {
        "id": "DV4o7cusr7u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIgMKmLvwvRT",
        "outputId": "f025fd03-d06e-4bb3-be6b-9c8996f2c908"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.1 colorlog-6.8.0 optuna-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective (trial):\n",
        "\n",
        "  hidden_layers_num = trial.suggest_int('hidden_layers_num', 5, 8)\n",
        "  number_epochs = trial.suggest_int('number_epochs', 10, 15)\n",
        "\n",
        "  model = MNISTConvNet(hidden_layers_num)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "  for epochs in range(number_epochs):\n",
        "\n",
        "    losses = 0\n",
        "\n",
        "    for input, label in trainloader:\n",
        "      y_pred = model(input)\n",
        "\n",
        "      loss = loss_fn(y_pred, label)\n",
        "\n",
        "      losses += (loss.item())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "    res = losses / len(trainloader)\n",
        "  return res"
      ],
      "metadata": {
        "id": "WkcMwNBLw27O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(objective, n_trials=10, n_jobs=-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJIpwaYHjGxB",
        "outputId": "5578bf27-abc4-4003-b2bd-f81f7f8c6751"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-21 14:32:37,714] A new study created in memory with name: no-name-10fa4310-0238-4798-9a2e-0a844113f089\n",
            "[I 2023-12-21 14:43:25,015] Trial 0 finished with value: 0.7195630326588949 and parameters: {'hidden_layers_num': 7, 'number_epochs': 10}. Best is trial 0 with value: 0.7195630326588949.\n",
            "[I 2023-12-21 14:45:15,282] Trial 1 finished with value: 0.6679180945158005 and parameters: {'hidden_layers_num': 8, 'number_epochs': 11}. Best is trial 1 with value: 0.6679180945158005.\n",
            "[I 2023-12-21 14:54:16,851] Trial 2 finished with value: 0.5590140865246455 and parameters: {'hidden_layers_num': 6, 'number_epochs': 11}. Best is trial 2 with value: 0.5590140865246455.\n",
            "[I 2023-12-21 15:01:07,707] Trial 3 finished with value: 0.30409573155641556 and parameters: {'hidden_layers_num': 7, 'number_epochs': 15}. Best is trial 3 with value: 0.30409573155641556.\n",
            "[I 2023-12-21 15:06:11,103] Trial 4 finished with value: 0.4979361178557078 and parameters: {'hidden_layers_num': 6, 'number_epochs': 12}. Best is trial 3 with value: 0.30409573155641556.\n",
            "[I 2023-12-21 15:13:26,239] Trial 5 finished with value: 0.46924972972075146 and parameters: {'hidden_layers_num': 5, 'number_epochs': 13}. Best is trial 3 with value: 0.30409573155641556.\n",
            "[I 2023-12-21 15:18:28,940] Trial 6 finished with value: 0.36090069490273796 and parameters: {'hidden_layers_num': 5, 'number_epochs': 13}. Best is trial 3 with value: 0.30409573155641556.\n",
            "[I 2023-12-21 15:23:24,055] Trial 7 finished with value: 0.7145564920584361 and parameters: {'hidden_layers_num': 6, 'number_epochs': 10}. Best is trial 3 with value: 0.30409573155641556.\n",
            "[I 2023-12-21 15:28:43,532] Trial 8 finished with value: 0.49244251736005146 and parameters: {'hidden_layers_num': 5, 'number_epochs': 11}. Best is trial 3 with value: 0.30409573155641556.\n",
            "[I 2023-12-21 15:32:20,162] Trial 9 finished with value: 0.3399311479369799 and parameters: {'hidden_layers_num': 5, 'number_epochs': 15}. Best is trial 3 with value: 0.30409573155641556.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can notice that the best hyperparameters are:\n",
        "hidden_layer = 5\n",
        "number_epochs = 15"
      ],
      "metadata": {
        "id": "gUdO-kHEGNMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(study.best_params)"
      ],
      "metadata": {
        "id": "DKKTPhDnjJjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f24588-8d96-43c8-fd2c-d48ce5bbe7b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hidden_layers_num': 7, 'number_epochs': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from optuna.visualization import plot_optimization_history\n",
        "\n",
        "plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "9NvDBXNEihOl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c24eb5a8-2ff5-4a5f-b367-5437b7578f0b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"2d2069d1-18a5-40eb-86c7-2c38253f374a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2d2069d1-18a5-40eb-86c7-2c38253f374a\")) {                    Plotly.newPlot(                        \"2d2069d1-18a5-40eb-86c7-2c38253f374a\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9],\"y\":[0.7195630326588949,0.6679180945158005,0.5590140865246455,0.30409573155641556,0.4979361178557078,0.46924972972075146,0.36090069490273796,0.7145564920584361,0.49244251736005146,0.3399311479369799],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9],\"y\":[0.7195630326588949,0.6679180945158005,0.5590140865246455,0.30409573155641556,0.30409573155641556,0.30409573155641556,0.30409573155641556,0.30409573155641556,0.30409573155641556,0.30409573155641556],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2d2069d1-18a5-40eb-86c7-2c38253f374a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will use optuna to select the model with the best params."
      ],
      "metadata": {
        "id": "GH242IGRtQxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = MNISTConvNet(7)\n",
        "best_model"
      ],
      "metadata": {
        "id": "BeaiAR_6tQZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "885e17a9-3808-4096-c525-9c75966839e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNISTConvNet(\n",
              "  (f1): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
              "  (act1): Sigmoid()\n",
              "  (fcX): ModuleList(\n",
              "    (0-6): 7 x Linear(in_features=300, out_features=300, bias=True)\n",
              "  )\n",
              "  (act2): Sigmoid()\n",
              "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
              "  (act3): Sigmoid()\n",
              "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And train again the model to evaluate with the best params."
      ],
      "metadata": {
        "id": "3l0g-rSdt-mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 15\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(best_model.parameters(), lr=0.001, momentum=0.9) #SGD = Stochastic gradient descent\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  losses = []\n",
        "  #training\n",
        "  for inputs, labels in trainloader:\n",
        "\n",
        "    y_pred = best_model(inputs)\n",
        "    loss = loss_fn(y_pred, labels)\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'Epoch {epoch + 1} --> loss = {np.mean(losses)}')\n",
        "\n",
        "  acc = 0\n",
        "  count = 0\n",
        "  for inputs, labels in testloader:\n",
        "\n",
        "    y_pred = best_model(inputs)\n",
        "\n",
        "    acc += (torch.argmax(y_pred,1) == labels).float().sum()\n",
        "    count += len(labels)\n",
        "\n",
        "  acc /= count\n",
        "\n",
        "  print(f'Epoch {epoch + 1} --> model accuracy = {acc * 100}')"
      ],
      "metadata": {
        "id": "cC71n2xhk0g3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9ae3ac-f4bd-4fe0-8574-d4e987e3372d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 --> loss = 2.303490075302124\n",
            "Epoch 1 --> model accuracy = 11.350000381469727\n",
            "Epoch 2 --> loss = 2.3026676475524903\n",
            "Epoch 2 --> model accuracy = 11.350000381469727\n",
            "Epoch 3 --> loss = 2.3017494482676186\n",
            "Epoch 3 --> model accuracy = 11.350000381469727\n",
            "Epoch 4 --> loss = 2.29985101331075\n",
            "Epoch 4 --> model accuracy = 19.799999237060547\n",
            "Epoch 5 --> loss = 2.194058504041036\n",
            "Epoch 5 --> model accuracy = 29.96000099182129\n",
            "Epoch 6 --> loss = 1.6027606295903525\n",
            "Epoch 6 --> model accuracy = 45.33000183105469\n",
            "Epoch 7 --> loss = 1.2425674817403158\n",
            "Epoch 7 --> model accuracy = 57.459999084472656\n",
            "Epoch 8 --> loss = 1.079195855553945\n",
            "Epoch 8 --> model accuracy = 66.40999603271484\n",
            "Epoch 9 --> loss = 0.8911442278067271\n",
            "Epoch 9 --> model accuracy = 74.16999816894531\n",
            "Epoch 10 --> loss = 0.7742028901576996\n",
            "Epoch 10 --> model accuracy = 75.51000213623047\n",
            "Epoch 11 --> loss = 0.7008344919204712\n",
            "Epoch 11 --> model accuracy = 78.33999633789062\n",
            "Epoch 12 --> loss = 0.6165890524148941\n",
            "Epoch 12 --> model accuracy = 80.02999877929688\n",
            "Epoch 13 --> loss = 0.5205511844317118\n",
            "Epoch 13 --> model accuracy = 86.44999694824219\n",
            "Epoch 14 --> loss = 0.43426227269570034\n",
            "Epoch 14 --> model accuracy = 89.52000427246094\n",
            "Epoch 15 --> loss = 0.35453559360901515\n",
            "Epoch 15 --> model accuracy = 91.20999908447266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end, we can see that with this hyperparameter optimization the accuracy will reach 91.21%!"
      ],
      "metadata": {
        "id": "94QpuxvSda-o"
      }
    }
  ]
}