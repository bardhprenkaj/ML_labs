{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5AYt3Cn35zA"
      },
      "source": [
        "**Challenge: Implement a Multiclass Classification Neural Network using PyTorch**\n",
        "\n",
        "Objective:\n",
        "Build a neural network using PyTorch to predict handwritten digits of MNIST.\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. **Data Preparation**: Load the MNIST dataset using ```torchvision.datasets.MNIST```. Standardize/normalize the features. Split the dataset into training and testing sets using, for example, ```sklearn.model_selection.train_test_split()```. **Bonus scores**: *use PyTorch's built-* ```DataLoader``` *to split the dataset*.\n",
        "\n",
        "2. **Neural Network Architecture**: Define a simple feedforward neural network using PyTorch's ```nn.Module```. Design the input layer to match the number of features in the MNIST dataset and the output layer to have as many neurons as there are classes (10). You can experiment with the number of hidden layers and neurons to optimize the performance. **Bonus scores**: *Make your architecture flexibile to have as many hidden layers as the user wants, and use hyperparameter optimization to select the best number of hidden layeres.*\n",
        "\n",
        "3. **Loss Function and Optimizer**: Choose an appropriate loss function for multiclass classification. Select an optimizer, like SGD (Stochastic Gradient Descent) or Adam.\n",
        "\n",
        "4. **Training**: Write a training loop to iterate over the dataset.\n",
        "Forward pass the input through the network, calculate the loss, and perform backpropagation. Update the weights of the network using the chosen optimizer.\n",
        "\n",
        "5. **Testing**: Evaluate the trained model on the test set. Calculate the accuracy of the model.\n",
        "\n",
        "6. **Optimization**: Experiment with hyperparameters (learning rate, number of epochs, etc.) to optimize the model's performance. Consider adjusting the neural network architecture for better results. **Notice that you can't use the optimization algorithms from scikit-learn that we saw in lab1: e.g.,** ```GridSearchCV```.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "id": "5XLynrxJ33v6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision as tv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-GBtFOXy_mt"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaQ1w6vt6Gs3"
      },
      "source": [
        "## Loading and normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {
        "id": "JUe2XwoCn4TI"
      },
      "outputs": [],
      "source": [
        "# The Normalize transform needs the mean and std of the dataset, but we need to load it first to\n",
        "# be able to calculate it. It will be modified later with the correct values.\n",
        "transforms = tv.transforms.Compose([tv.transforms.ToTensor(), tv.transforms.Normalize(0, 0)])\n",
        "\n",
        "train_set = tv.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transforms)\n",
        "test_set = tv.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(33.31842041015625, 78.56748962402344)"
            ]
          },
          "execution_count": 438,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def calc_mean_std(tensor):\n",
        "    mean = tensor.float().mean().item()\n",
        "    std = tensor.float().std().item()\n",
        "    return mean, std\n",
        "\n",
        "mean, std = calc_mean_std(train_set.data)\n",
        "mean, std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.13066047219669116, 0.30810780244715075)"
            ]
          },
          "execution_count": 439,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ToTensor maps the pixel range [0, 255] to tensor range [0, 1]\n",
        "# The mean and std were calculated from the images so they have to be adjusted\n",
        "\n",
        "mean_after_tensor = mean / 255\n",
        "std_after_tensor = std / 255\n",
        "\n",
        "mean_after_tensor, std_after_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {},
      "outputs": [],
      "source": [
        "transforms.transforms[-1].mean = mean_after_tensor\n",
        "transforms.transforms[-1].std = std_after_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mYvssYA6KqI"
      },
      "source": [
        "## Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {
        "id": "jkrtdKjpoRoK"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_set, batch_size, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMkEw7ek6j3F"
      },
      "source": [
        "# Neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfzruJoo_Ycu",
        "outputId": "2d93e949-20c2-458d-aad7-5dac3a4d1573"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "execution_count": 442,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Number of features after flattening\n",
        "feats = np.prod(train_set.data.shape[1:])\n",
        "feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 443,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8IBAyxOavwD",
        "outputId": "79b32440-2d5b-4ecb-a83b-567282fe3a54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 443,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes = len(train_set.classes)\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 444,
      "metadata": {
        "id": "Ej4CmPMh_MxJ"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_layers, hidden_neurons, dropout_rate):\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.input = nn.Linear(feats, hidden_neurons)\n",
        "        self.act_input = nn.ReLU()\n",
        "\n",
        "        hidden = []\n",
        "        for _ in range(hidden_layers):\n",
        "            hidden.append(nn.Linear(hidden_neurons, hidden_neurons))\n",
        "            hidden.append(nn.ReLU())\n",
        "            hidden.append(nn.Dropout(dropout_rate))\n",
        "\n",
        "        self.hidden = nn.Sequential(*hidden)\n",
        "\n",
        "        self.output = nn.Linear(hidden_neurons, classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.input(x)\n",
        "        x = self.hidden(x)\n",
        "        x = self.output(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {
        "id": "eKR8ufJznuiQ"
      },
      "outputs": [],
      "source": [
        "# We will try without dropout layers first\n",
        "model = Net(2, 128, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWQAB7VakeEl"
      },
      "source": [
        "# Loss function and optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzWOwip8kjbO"
      },
      "source": [
        "Since we are dealing with a non-binary classification problem, the best choice for a loss function is Cross Entropy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 446,
      "metadata": {
        "id": "bWEKGJOZkgep"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the optimizer, we will try SDG first but of course we will test other optimizers in the optimization section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 447,
      "metadata": {
        "id": "ScZ7v3jxngHs"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IySskDwtppDx"
      },
      "source": [
        "# Training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "fMIhpL01prRc",
        "outputId": "7328cafd-1e1a-4a02-d92e-f75c5a0339aa"
      },
      "outputs": [],
      "source": [
        "def train(n_epochs, model, optimizer):\n",
        "    for epoch in range(n_epochs):\n",
        "        losses = []\n",
        "\n",
        "        # Update params\n",
        "        model.train()\n",
        "        tp = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            pred = model(inputs)\n",
        "            loss = loss_fn(pred, labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tp += (pred.argmax(1) == labels).float().sum()\n",
        "\n",
        "        acc_train = tp / len(train_loader.dataset)\n",
        "\n",
        "        # Evaluate epoch\n",
        "        model.eval()\n",
        "        tp = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                pred = model(inputs)\n",
        "\n",
        "                tp += (pred.argmax(1) == labels).float().sum()\n",
        "\n",
        "        acc_test = tp / len(test_loader.dataset)\n",
        "\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch + 1} | \" +\n",
        "            f\"Acc: Train {acc_train * 100:.2f}% Test {acc_test * 100:.2f}% | \" +\n",
        "            f\"Avg Loss: {np.mean(losses):.4f} Min Loss: {np.min(losses):.4f}\"\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 449,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Acc: Train 89.31% Test 94.77% | Avg Loss: 0.3647 Min Loss: 0.0289\n",
            "Epoch 2 | Acc: Train 95.79% Test 95.95% | Avg Loss: 0.1355 Min Loss: 0.0134\n",
            "Epoch 3 | Acc: Train 97.01% Test 96.66% | Avg Loss: 0.0956 Min Loss: 0.0058\n",
            "Epoch 4 | Acc: Train 97.56% Test 96.80% | Avg Loss: 0.0763 Min Loss: 0.0034\n",
            "Epoch 5 | Acc: Train 98.00% Test 97.12% | Avg Loss: 0.0636 Min Loss: 0.0016\n",
            "Epoch 6 | Acc: Train 98.18% Test 97.43% | Avg Loss: 0.0534 Min Loss: 0.0017\n",
            "Epoch 7 | Acc: Train 98.49% Test 97.00% | Avg Loss: 0.0457 Min Loss: 0.0017\n",
            "Epoch 8 | Acc: Train 98.64% Test 97.21% | Avg Loss: 0.0391 Min Loss: 0.0007\n",
            "Epoch 9 | Acc: Train 98.76% Test 97.53% | Avg Loss: 0.0351 Min Loss: 0.0006\n",
            "Epoch 10 | Acc: Train 98.93% Test 97.66% | Avg Loss: 0.0309 Min Loss: 0.0003\n",
            "Epoch 11 | Acc: Train 99.09% Test 97.56% | Avg Loss: 0.0260 Min Loss: 0.0002\n",
            "Epoch 12 | Acc: Train 99.05% Test 97.71% | Avg Loss: 0.0256 Min Loss: 0.0003\n",
            "Epoch 13 | Acc: Train 99.25% Test 97.54% | Avg Loss: 0.0206 Min Loss: 0.0002\n",
            "Epoch 14 | Acc: Train 99.35% Test 97.53% | Avg Loss: 0.0177 Min Loss: 0.0001\n",
            "Epoch 15 | Acc: Train 99.40% Test 97.61% | Avg Loss: 0.0165 Min Loss: 0.0000\n",
            "Epoch 16 | Acc: Train 99.44% Test 97.68% | Avg Loss: 0.0149 Min Loss: 0.0001\n",
            "Epoch 17 | Acc: Train 99.33% Test 97.73% | Avg Loss: 0.0175 Min Loss: 0.0000\n",
            "Epoch 18 | Acc: Train 99.45% Test 97.53% | Avg Loss: 0.0142 Min Loss: 0.0000\n",
            "Epoch 19 | Acc: Train 99.50% Test 97.80% | Avg Loss: 0.0133 Min Loss: 0.0000\n",
            "Epoch 20 | Acc: Train 99.60% Test 97.67% | Avg Loss: 0.0103 Min Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "train(20, model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dropout and learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we can see that the model is slightly overfitting, as the accuracy on the test set pleateaus at around $97\\%-98\\%$ but on the train set it continues going up until $99.60\\%$ (it would be more if we further increased the epochs). Let's see what happens when we use the dropout layers that, already getting ahead of the problem, we added before.\n",
        "\n",
        "The original model starts to overfit around epoch $3$, with a test accuracy of around $96\\%$. *Early stopping* would be a good technique to avoid overfitting here, as that accuracy is alredy quite high, but maybe we can do better. We will use that as a reference point for the following optimizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 460,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Acc: Train 83.76% Test 93.68% | Avg Loss: 0.5237 Min Loss: 0.0703\n",
            "Epoch 2 | Acc: Train 92.12% Test 94.95% | Avg Loss: 0.2651 Min Loss: 0.0529\n",
            "Epoch 3 | Acc: Train 93.46% Test 95.92% | Avg Loss: 0.2216 Min Loss: 0.0158\n",
            "Epoch 4 | Acc: Train 94.06% Test 95.98% | Avg Loss: 0.1974 Min Loss: 0.0323\n",
            "Epoch 5 | Acc: Train 94.52% Test 96.55% | Avg Loss: 0.1863 Min Loss: 0.0238\n",
            "Epoch 6 | Acc: Train 94.95% Test 96.52% | Avg Loss: 0.1675 Min Loss: 0.0220\n",
            "Epoch 7 | Acc: Train 95.17% Test 96.72% | Avg Loss: 0.1615 Min Loss: 0.0173\n",
            "Epoch 8 | Acc: Train 95.53% Test 97.09% | Avg Loss: 0.1536 Min Loss: 0.0121\n",
            "Epoch 9 | Acc: Train 95.40% Test 96.69% | Avg Loss: 0.1540 Min Loss: 0.0134\n",
            "Epoch 10 | Acc: Train 95.56% Test 96.84% | Avg Loss: 0.1431 Min Loss: 0.0064\n",
            "Epoch 11 | Acc: Train 95.78% Test 96.49% | Avg Loss: 0.1399 Min Loss: 0.0112\n",
            "Epoch 12 | Acc: Train 95.90% Test 96.68% | Avg Loss: 0.1370 Min Loss: 0.0075\n",
            "Epoch 13 | Acc: Train 95.90% Test 97.24% | Avg Loss: 0.1351 Min Loss: 0.0103\n",
            "Epoch 14 | Acc: Train 96.07% Test 97.08% | Avg Loss: 0.1312 Min Loss: 0.0092\n",
            "Epoch 15 | Acc: Train 96.12% Test 97.00% | Avg Loss: 0.1288 Min Loss: 0.0076\n",
            "Epoch 16 | Acc: Train 96.13% Test 97.36% | Avg Loss: 0.1314 Min Loss: 0.0094\n",
            "Epoch 17 | Acc: Train 96.12% Test 97.09% | Avg Loss: 0.1283 Min Loss: 0.0051\n",
            "Epoch 18 | Acc: Train 96.25% Test 97.20% | Avg Loss: 0.1213 Min Loss: 0.0076\n",
            "Epoch 19 | Acc: Train 96.28% Test 97.06% | Avg Loss: 0.1226 Min Loss: 0.0075\n",
            "Epoch 20 | Acc: Train 96.35% Test 97.18% | Avg Loss: 0.1205 Min Loss: 0.0040\n",
            "Epoch 21 | Acc: Train 96.26% Test 97.44% | Avg Loss: 0.1229 Min Loss: 0.0027\n",
            "Epoch 22 | Acc: Train 96.51% Test 97.01% | Avg Loss: 0.1142 Min Loss: 0.0041\n",
            "Epoch 23 | Acc: Train 96.40% Test 97.43% | Avg Loss: 0.1195 Min Loss: 0.0041\n",
            "Epoch 24 | Acc: Train 96.42% Test 97.28% | Avg Loss: 0.1175 Min Loss: 0.0063\n",
            "Epoch 25 | Acc: Train 96.45% Test 97.37% | Avg Loss: 0.1145 Min Loss: 0.0031\n",
            "Epoch 26 | Acc: Train 96.39% Test 97.32% | Avg Loss: 0.1184 Min Loss: 0.0055\n",
            "Epoch 27 | Acc: Train 96.58% Test 97.56% | Avg Loss: 0.1112 Min Loss: 0.0053\n",
            "Epoch 28 | Acc: Train 96.67% Test 97.39% | Avg Loss: 0.1092 Min Loss: 0.0049\n",
            "Epoch 29 | Acc: Train 96.68% Test 97.58% | Avg Loss: 0.1099 Min Loss: 0.0057\n",
            "Epoch 30 | Acc: Train 96.57% Test 97.37% | Avg Loss: 0.1127 Min Loss: 0.0041\n",
            "Epoch 31 | Acc: Train 96.70% Test 97.44% | Avg Loss: 0.1083 Min Loss: 0.0041\n",
            "Epoch 32 | Acc: Train 96.64% Test 97.28% | Avg Loss: 0.1080 Min Loss: 0.0020\n",
            "Epoch 33 | Acc: Train 96.74% Test 97.51% | Avg Loss: 0.1066 Min Loss: 0.0046\n",
            "Epoch 34 | Acc: Train 96.56% Test 97.51% | Avg Loss: 0.1108 Min Loss: 0.0023\n",
            "Epoch 35 | Acc: Train 96.65% Test 97.20% | Avg Loss: 0.1099 Min Loss: 0.0040\n",
            "Epoch 36 | Acc: Train 96.72% Test 97.29% | Avg Loss: 0.1091 Min Loss: 0.0065\n",
            "Epoch 37 | Acc: Train 96.81% Test 97.45% | Avg Loss: 0.1043 Min Loss: 0.0029\n",
            "Epoch 38 | Acc: Train 96.63% Test 97.33% | Avg Loss: 0.1106 Min Loss: 0.0040\n",
            "Epoch 39 | Acc: Train 96.76% Test 97.30% | Avg Loss: 0.1037 Min Loss: 0.0074\n",
            "Epoch 40 | Acc: Train 96.77% Test 97.45% | Avg Loss: 0.1060 Min Loss: 0.0023\n",
            "Epoch 41 | Acc: Train 96.88% Test 97.05% | Avg Loss: 0.1022 Min Loss: 0.0014\n",
            "Epoch 42 | Acc: Train 96.89% Test 97.46% | Avg Loss: 0.1018 Min Loss: 0.0024\n",
            "Epoch 43 | Acc: Train 96.83% Test 97.49% | Avg Loss: 0.1029 Min Loss: 0.0038\n",
            "Epoch 44 | Acc: Train 96.80% Test 97.50% | Avg Loss: 0.1023 Min Loss: 0.0042\n",
            "Epoch 45 | Acc: Train 96.73% Test 97.41% | Avg Loss: 0.1070 Min Loss: 0.0038\n",
            "Epoch 46 | Acc: Train 96.94% Test 97.41% | Avg Loss: 0.1006 Min Loss: 0.0023\n",
            "Epoch 47 | Acc: Train 96.94% Test 97.40% | Avg Loss: 0.1011 Min Loss: 0.0038\n",
            "Epoch 48 | Acc: Train 96.90% Test 97.48% | Avg Loss: 0.1028 Min Loss: 0.0017\n",
            "Epoch 49 | Acc: Train 97.09% Test 97.41% | Avg Loss: 0.0949 Min Loss: 0.0018\n",
            "Epoch 50 | Acc: Train 96.81% Test 97.36% | Avg Loss: 0.1022 Min Loss: 0.0015\n"
          ]
        }
      ],
      "source": [
        "model = Net(2, 128, 0.3)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "train(50, model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After testing several dropout rates, also adjusting the learning rate and epochs to account for the extra slowness in training that comes with dropout, a rate of $0.3$ is what seems optimal. We won't show the output for each test to avoid cluttering the notebook, but these were the most remarkable results:\n",
        "\n",
        "- With $0.5$ and $0.4$, using $lr=0.01$, accuracy started to plateau around $97\\%$, which is better than before but we wanted to see if it could do better.\n",
        "- With $0.3$ , using $lr=0.01$, accuracy went up to $97.5\\%$, even going up to $98\\%$ in some runs.\n",
        "- With $0.2$, it started overfitting again after around $12$ epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try with **Adam**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 468,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Acc: Train 90.34% Test 95.16% | Avg Loss: 0.3194 Min Loss: 0.0314\n",
            "Epoch 2 | Acc: Train 94.40% Test 96.05% | Avg Loss: 0.1825 Min Loss: 0.0210\n",
            "Epoch 3 | Acc: Train 95.31% Test 96.57% | Avg Loss: 0.1523 Min Loss: 0.0083\n",
            "Epoch 4 | Acc: Train 95.74% Test 96.79% | Avg Loss: 0.1368 Min Loss: 0.0155\n",
            "Epoch 5 | Acc: Train 96.04% Test 96.52% | Avg Loss: 0.1278 Min Loss: 0.0105\n",
            "Epoch 6 | Acc: Train 96.34% Test 97.01% | Avg Loss: 0.1170 Min Loss: 0.0049\n",
            "Epoch 7 | Acc: Train 96.58% Test 96.87% | Avg Loss: 0.1101 Min Loss: 0.0051\n",
            "Epoch 8 | Acc: Train 96.48% Test 97.31% | Avg Loss: 0.1107 Min Loss: 0.0052\n",
            "Epoch 9 | Acc: Train 96.69% Test 97.24% | Avg Loss: 0.1054 Min Loss: 0.0052\n",
            "Epoch 10 | Acc: Train 96.78% Test 96.88% | Avg Loss: 0.1007 Min Loss: 0.0029\n",
            "Epoch 11 | Acc: Train 96.85% Test 97.05% | Avg Loss: 0.1006 Min Loss: 0.0033\n",
            "Epoch 12 | Acc: Train 96.93% Test 97.16% | Avg Loss: 0.0958 Min Loss: 0.0038\n",
            "Epoch 13 | Acc: Train 96.91% Test 97.39% | Avg Loss: 0.0991 Min Loss: 0.0025\n",
            "Epoch 14 | Acc: Train 97.01% Test 97.05% | Avg Loss: 0.0949 Min Loss: 0.0020\n",
            "Epoch 15 | Acc: Train 97.10% Test 97.05% | Avg Loss: 0.0929 Min Loss: 0.0015\n",
            "Epoch 16 | Acc: Train 97.05% Test 97.66% | Avg Loss: 0.0938 Min Loss: 0.0041\n",
            "Epoch 17 | Acc: Train 97.24% Test 97.63% | Avg Loss: 0.0872 Min Loss: 0.0014\n",
            "Epoch 18 | Acc: Train 97.17% Test 97.34% | Avg Loss: 0.0873 Min Loss: 0.0016\n",
            "Epoch 19 | Acc: Train 97.29% Test 97.34% | Avg Loss: 0.0851 Min Loss: 0.0013\n",
            "Epoch 20 | Acc: Train 97.32% Test 97.57% | Avg Loss: 0.0853 Min Loss: 0.0012\n",
            "Epoch 21 | Acc: Train 97.29% Test 97.34% | Avg Loss: 0.0871 Min Loss: 0.0006\n",
            "Epoch 22 | Acc: Train 97.40% Test 97.40% | Avg Loss: 0.0808 Min Loss: 0.0008\n",
            "Epoch 23 | Acc: Train 97.42% Test 97.35% | Avg Loss: 0.0811 Min Loss: 0.0014\n",
            "Epoch 24 | Acc: Train 97.38% Test 97.59% | Avg Loss: 0.0827 Min Loss: 0.0015\n",
            "Epoch 25 | Acc: Train 97.49% Test 97.57% | Avg Loss: 0.0804 Min Loss: 0.0012\n",
            "Epoch 26 | Acc: Train 97.58% Test 97.15% | Avg Loss: 0.0760 Min Loss: 0.0005\n",
            "Epoch 27 | Acc: Train 97.43% Test 97.41% | Avg Loss: 0.0812 Min Loss: 0.0008\n",
            "Epoch 28 | Acc: Train 97.43% Test 96.91% | Avg Loss: 0.0797 Min Loss: 0.0010\n",
            "Epoch 29 | Acc: Train 97.46% Test 97.23% | Avg Loss: 0.0786 Min Loss: 0.0011\n",
            "Epoch 30 | Acc: Train 97.60% Test 97.53% | Avg Loss: 0.0761 Min Loss: 0.0005\n",
            "Epoch 31 | Acc: Train 97.63% Test 97.49% | Avg Loss: 0.0762 Min Loss: 0.0003\n",
            "Epoch 32 | Acc: Train 97.67% Test 97.38% | Avg Loss: 0.0740 Min Loss: 0.0003\n",
            "Epoch 33 | Acc: Train 97.61% Test 97.51% | Avg Loss: 0.0756 Min Loss: 0.0005\n",
            "Epoch 34 | Acc: Train 97.60% Test 97.50% | Avg Loss: 0.0763 Min Loss: 0.0005\n",
            "Epoch 35 | Acc: Train 97.69% Test 97.39% | Avg Loss: 0.0761 Min Loss: 0.0004\n",
            "Epoch 36 | Acc: Train 97.73% Test 97.30% | Avg Loss: 0.0721 Min Loss: 0.0001\n",
            "Epoch 37 | Acc: Train 97.67% Test 97.36% | Avg Loss: 0.0734 Min Loss: 0.0009\n",
            "Epoch 38 | Acc: Train 97.75% Test 97.41% | Avg Loss: 0.0743 Min Loss: 0.0007\n",
            "Epoch 39 | Acc: Train 97.80% Test 97.06% | Avg Loss: 0.0687 Min Loss: 0.0010\n",
            "Epoch 40 | Acc: Train 97.72% Test 97.34% | Avg Loss: 0.0725 Min Loss: 0.0005\n",
            "Epoch 41 | Acc: Train 97.76% Test 97.23% | Avg Loss: 0.0718 Min Loss: 0.0007\n",
            "Epoch 42 | Acc: Train 97.88% Test 97.55% | Avg Loss: 0.0674 Min Loss: 0.0003\n",
            "Epoch 43 | Acc: Train 97.71% Test 97.12% | Avg Loss: 0.0741 Min Loss: 0.0003\n",
            "Epoch 44 | Acc: Train 97.86% Test 97.35% | Avg Loss: 0.0706 Min Loss: 0.0004\n",
            "Epoch 45 | Acc: Train 97.73% Test 97.31% | Avg Loss: 0.0736 Min Loss: 0.0002\n",
            "Epoch 46 | Acc: Train 97.82% Test 97.13% | Avg Loss: 0.0691 Min Loss: 0.0001\n",
            "Epoch 47 | Acc: Train 97.84% Test 97.09% | Avg Loss: 0.0713 Min Loss: 0.0005\n",
            "Epoch 48 | Acc: Train 97.87% Test 97.44% | Avg Loss: 0.0692 Min Loss: 0.0004\n",
            "Epoch 49 | Acc: Train 97.86% Test 97.16% | Avg Loss: 0.0694 Min Loss: 0.0002\n",
            "Epoch 50 | Acc: Train 97.95% Test 97.35% | Avg Loss: 0.0640 Min Loss: 0.0003\n"
          ]
        }
      ],
      "source": [
        "model = Net(1, 128, 0.3)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train(50, model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since Adam doesn't have momentum, it's more likely that the gradient explodes in later epochs with a big learning rate.\n",
        "\n",
        "- $lr=0.01$ caused the gradients to explode, as expected, and accuracy decreased continuously.\n",
        "- $lr=0.001$ yielded slightly worse results than **SGD** in the previous section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Number of hidden layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is important to watch out for overfitting as it is a known effect of incresing the depth of neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 463,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Acc: Train 89.14% Test 94.56% | Avg Loss: 0.3583 Min Loss: 0.0571\n",
            "Epoch 2 | Acc: Train 94.56% Test 96.24% | Avg Loss: 0.1813 Min Loss: 0.0263\n",
            "Epoch 3 | Acc: Train 95.47% Test 96.76% | Avg Loss: 0.1497 Min Loss: 0.0119\n",
            "Epoch 4 | Acc: Train 96.07% Test 96.65% | Avg Loss: 0.1302 Min Loss: 0.0089\n",
            "Epoch 5 | Acc: Train 96.32% Test 97.16% | Avg Loss: 0.1180 Min Loss: 0.0078\n",
            "Epoch 6 | Acc: Train 96.62% Test 97.29% | Avg Loss: 0.1107 Min Loss: 0.0051\n",
            "Epoch 7 | Acc: Train 96.65% Test 97.15% | Avg Loss: 0.1053 Min Loss: 0.0079\n",
            "Epoch 8 | Acc: Train 96.97% Test 97.22% | Avg Loss: 0.0979 Min Loss: 0.0034\n",
            "Epoch 9 | Acc: Train 96.83% Test 97.47% | Avg Loss: 0.0965 Min Loss: 0.0063\n",
            "Epoch 10 | Acc: Train 97.08% Test 97.43% | Avg Loss: 0.0900 Min Loss: 0.0060\n",
            "Epoch 11 | Acc: Train 97.18% Test 97.44% | Avg Loss: 0.0872 Min Loss: 0.0032\n",
            "Epoch 12 | Acc: Train 97.25% Test 97.46% | Avg Loss: 0.0846 Min Loss: 0.0030\n",
            "Epoch 13 | Acc: Train 97.31% Test 97.33% | Avg Loss: 0.0821 Min Loss: 0.0023\n",
            "Epoch 14 | Acc: Train 97.36% Test 97.41% | Avg Loss: 0.0819 Min Loss: 0.0014\n",
            "Epoch 15 | Acc: Train 97.50% Test 97.57% | Avg Loss: 0.0778 Min Loss: 0.0031\n",
            "Epoch 16 | Acc: Train 97.57% Test 97.75% | Avg Loss: 0.0756 Min Loss: 0.0042\n",
            "Epoch 17 | Acc: Train 97.52% Test 97.64% | Avg Loss: 0.0750 Min Loss: 0.0029\n",
            "Epoch 18 | Acc: Train 97.49% Test 97.54% | Avg Loss: 0.0751 Min Loss: 0.0013\n",
            "Epoch 19 | Acc: Train 97.72% Test 97.59% | Avg Loss: 0.0685 Min Loss: 0.0013\n",
            "Epoch 20 | Acc: Train 97.66% Test 97.54% | Avg Loss: 0.0713 Min Loss: 0.0022\n",
            "Epoch 21 | Acc: Train 97.69% Test 97.32% | Avg Loss: 0.0692 Min Loss: 0.0018\n",
            "Epoch 22 | Acc: Train 97.68% Test 97.54% | Avg Loss: 0.0705 Min Loss: 0.0017\n",
            "Epoch 23 | Acc: Train 97.67% Test 97.61% | Avg Loss: 0.0708 Min Loss: 0.0021\n",
            "Epoch 24 | Acc: Train 97.64% Test 97.45% | Avg Loss: 0.0703 Min Loss: 0.0008\n",
            "Epoch 25 | Acc: Train 97.63% Test 97.32% | Avg Loss: 0.0705 Min Loss: 0.0012\n",
            "Epoch 26 | Acc: Train 97.74% Test 97.49% | Avg Loss: 0.0671 Min Loss: 0.0015\n",
            "Epoch 27 | Acc: Train 97.76% Test 97.32% | Avg Loss: 0.0675 Min Loss: 0.0007\n",
            "Epoch 28 | Acc: Train 97.76% Test 97.59% | Avg Loss: 0.0671 Min Loss: 0.0012\n",
            "Epoch 29 | Acc: Train 97.96% Test 97.62% | Avg Loss: 0.0629 Min Loss: 0.0008\n",
            "Epoch 30 | Acc: Train 97.90% Test 97.61% | Avg Loss: 0.0627 Min Loss: 0.0018\n",
            "Epoch 31 | Acc: Train 97.84% Test 97.62% | Avg Loss: 0.0640 Min Loss: 0.0010\n",
            "Epoch 32 | Acc: Train 97.89% Test 97.78% | Avg Loss: 0.0637 Min Loss: 0.0007\n",
            "Epoch 33 | Acc: Train 97.94% Test 97.78% | Avg Loss: 0.0630 Min Loss: 0.0007\n",
            "Epoch 34 | Acc: Train 97.88% Test 97.57% | Avg Loss: 0.0639 Min Loss: 0.0009\n",
            "Epoch 35 | Acc: Train 98.12% Test 97.54% | Avg Loss: 0.0572 Min Loss: 0.0005\n",
            "Epoch 36 | Acc: Train 97.92% Test 97.44% | Avg Loss: 0.0620 Min Loss: 0.0004\n",
            "Epoch 37 | Acc: Train 97.97% Test 97.45% | Avg Loss: 0.0623 Min Loss: 0.0007\n",
            "Epoch 38 | Acc: Train 97.96% Test 97.54% | Avg Loss: 0.0612 Min Loss: 0.0016\n",
            "Epoch 39 | Acc: Train 98.06% Test 97.35% | Avg Loss: 0.0604 Min Loss: 0.0006\n",
            "Epoch 40 | Acc: Train 97.86% Test 97.40% | Avg Loss: 0.0642 Min Loss: 0.0013\n",
            "Epoch 41 | Acc: Train 98.11% Test 97.48% | Avg Loss: 0.0590 Min Loss: 0.0006\n",
            "Epoch 42 | Acc: Train 98.08% Test 97.55% | Avg Loss: 0.0572 Min Loss: 0.0011\n",
            "Epoch 43 | Acc: Train 97.99% Test 97.58% | Avg Loss: 0.0611 Min Loss: 0.0002\n",
            "Epoch 44 | Acc: Train 97.97% Test 97.49% | Avg Loss: 0.0607 Min Loss: 0.0005\n",
            "Epoch 45 | Acc: Train 98.05% Test 97.41% | Avg Loss: 0.0598 Min Loss: 0.0005\n",
            "Epoch 46 | Acc: Train 98.01% Test 97.59% | Avg Loss: 0.0604 Min Loss: 0.0004\n",
            "Epoch 47 | Acc: Train 98.12% Test 97.36% | Avg Loss: 0.0575 Min Loss: 0.0001\n",
            "Epoch 48 | Acc: Train 98.04% Test 97.44% | Avg Loss: 0.0597 Min Loss: 0.0005\n",
            "Epoch 49 | Acc: Train 98.04% Test 97.47% | Avg Loss: 0.0580 Min Loss: 0.0004\n",
            "Epoch 50 | Acc: Train 97.98% Test 97.41% | Avg Loss: 0.0616 Min Loss: 0.0003\n"
          ]
        }
      ],
      "source": [
        "model = Net(1, 128, 0.3)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "train(50, model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Neither $4$ nor $6$ layers improved accuracy.\n",
        "- Decreasing the number of layers to $1$ also maintained accuracy so by occam's razor, we will choose this number of layers.\n",
        "\n",
        "Decreasing the number of layers to 0 would cause the model to underfit as it gives it essentially no capacity to abstract and generalize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Number of neurons per hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 465,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Acc: Train 90.30% Test 94.85% | Avg Loss: 0.3253 Min Loss: 0.0454\n",
            "Epoch 2 | Acc: Train 95.31% Test 96.47% | Avg Loss: 0.1548 Min Loss: 0.0180\n",
            "Epoch 3 | Acc: Train 96.40% Test 96.94% | Avg Loss: 0.1174 Min Loss: 0.0078\n",
            "Epoch 4 | Acc: Train 96.89% Test 97.23% | Avg Loss: 0.0993 Min Loss: 0.0056\n",
            "Epoch 5 | Acc: Train 97.24% Test 97.35% | Avg Loss: 0.0860 Min Loss: 0.0054\n",
            "Epoch 6 | Acc: Train 97.50% Test 97.47% | Avg Loss: 0.0780 Min Loss: 0.0032\n",
            "Epoch 7 | Acc: Train 97.63% Test 97.68% | Avg Loss: 0.0710 Min Loss: 0.0026\n",
            "Epoch 8 | Acc: Train 97.77% Test 97.46% | Avg Loss: 0.0686 Min Loss: 0.0030\n",
            "Epoch 9 | Acc: Train 97.88% Test 97.80% | Avg Loss: 0.0625 Min Loss: 0.0026\n",
            "Epoch 10 | Acc: Train 98.11% Test 97.87% | Avg Loss: 0.0568 Min Loss: 0.0025\n",
            "Epoch 11 | Acc: Train 98.14% Test 97.82% | Avg Loss: 0.0543 Min Loss: 0.0009\n",
            "Epoch 12 | Acc: Train 98.31% Test 97.75% | Avg Loss: 0.0510 Min Loss: 0.0014\n",
            "Epoch 13 | Acc: Train 98.37% Test 97.86% | Avg Loss: 0.0478 Min Loss: 0.0011\n",
            "Epoch 14 | Acc: Train 98.40% Test 97.88% | Avg Loss: 0.0462 Min Loss: 0.0008\n",
            "Epoch 15 | Acc: Train 98.40% Test 97.88% | Avg Loss: 0.0451 Min Loss: 0.0010\n",
            "Epoch 16 | Acc: Train 98.57% Test 97.86% | Avg Loss: 0.0411 Min Loss: 0.0009\n",
            "Epoch 17 | Acc: Train 98.62% Test 98.02% | Avg Loss: 0.0400 Min Loss: 0.0010\n",
            "Epoch 18 | Acc: Train 98.57% Test 97.86% | Avg Loss: 0.0402 Min Loss: 0.0005\n",
            "Epoch 19 | Acc: Train 98.73% Test 97.99% | Avg Loss: 0.0366 Min Loss: 0.0004\n",
            "Epoch 20 | Acc: Train 98.62% Test 97.89% | Avg Loss: 0.0392 Min Loss: 0.0003\n",
            "Epoch 21 | Acc: Train 98.72% Test 97.95% | Avg Loss: 0.0370 Min Loss: 0.0004\n",
            "Epoch 22 | Acc: Train 98.84% Test 97.68% | Avg Loss: 0.0336 Min Loss: 0.0005\n",
            "Epoch 23 | Acc: Train 98.82% Test 97.91% | Avg Loss: 0.0330 Min Loss: 0.0003\n",
            "Epoch 24 | Acc: Train 98.88% Test 97.87% | Avg Loss: 0.0315 Min Loss: 0.0003\n",
            "Epoch 25 | Acc: Train 98.95% Test 97.88% | Avg Loss: 0.0292 Min Loss: 0.0001\n",
            "Epoch 26 | Acc: Train 98.97% Test 97.94% | Avg Loss: 0.0295 Min Loss: 0.0002\n",
            "Epoch 27 | Acc: Train 98.91% Test 98.01% | Avg Loss: 0.0302 Min Loss: 0.0002\n",
            "Epoch 28 | Acc: Train 98.89% Test 97.87% | Avg Loss: 0.0310 Min Loss: 0.0003\n",
            "Epoch 29 | Acc: Train 99.03% Test 98.07% | Avg Loss: 0.0268 Min Loss: 0.0001\n",
            "Epoch 30 | Acc: Train 99.01% Test 97.96% | Avg Loss: 0.0276 Min Loss: 0.0001\n",
            "Epoch 31 | Acc: Train 98.96% Test 98.11% | Avg Loss: 0.0286 Min Loss: 0.0001\n",
            "Epoch 32 | Acc: Train 99.08% Test 98.02% | Avg Loss: 0.0263 Min Loss: 0.0001\n",
            "Epoch 33 | Acc: Train 99.09% Test 97.99% | Avg Loss: 0.0257 Min Loss: 0.0001\n",
            "Epoch 34 | Acc: Train 99.05% Test 97.92% | Avg Loss: 0.0263 Min Loss: 0.0001\n",
            "Epoch 35 | Acc: Train 99.01% Test 97.91% | Avg Loss: 0.0292 Min Loss: 0.0001\n",
            "Epoch 36 | Acc: Train 98.98% Test 98.15% | Avg Loss: 0.0281 Min Loss: 0.0001\n",
            "Epoch 37 | Acc: Train 99.07% Test 97.83% | Avg Loss: 0.0265 Min Loss: 0.0001\n",
            "Epoch 38 | Acc: Train 99.01% Test 97.98% | Avg Loss: 0.0272 Min Loss: 0.0000\n",
            "Epoch 39 | Acc: Train 99.05% Test 97.87% | Avg Loss: 0.0264 Min Loss: 0.0001\n",
            "Epoch 40 | Acc: Train 99.11% Test 97.91% | Avg Loss: 0.0261 Min Loss: 0.0000\n",
            "Epoch 41 | Acc: Train 99.08% Test 97.98% | Avg Loss: 0.0269 Min Loss: 0.0000\n",
            "Epoch 42 | Acc: Train 99.08% Test 97.93% | Avg Loss: 0.0265 Min Loss: 0.0001\n",
            "Epoch 43 | Acc: Train 99.11% Test 97.82% | Avg Loss: 0.0269 Min Loss: 0.0001\n",
            "Epoch 44 | Acc: Train 99.09% Test 98.07% | Avg Loss: 0.0257 Min Loss: 0.0000\n",
            "Epoch 45 | Acc: Train 99.12% Test 98.08% | Avg Loss: 0.0246 Min Loss: 0.0001\n",
            "Epoch 46 | Acc: Train 99.11% Test 97.67% | Avg Loss: 0.0255 Min Loss: 0.0000\n",
            "Epoch 47 | Acc: Train 99.15% Test 98.02% | Avg Loss: 0.0246 Min Loss: 0.0000\n",
            "Epoch 48 | Acc: Train 99.21% Test 97.99% | Avg Loss: 0.0215 Min Loss: 0.0000\n",
            "Epoch 49 | Acc: Train 99.11% Test 97.84% | Avg Loss: 0.0258 Min Loss: 0.0000\n",
            "Epoch 50 | Acc: Train 99.21% Test 97.77% | Avg Loss: 0.0221 Min Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "model = Net(1, 256, 0.3)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "train(50, model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- $64$ neurons per layer made the model underfit.\n",
        "- $256$ overfitted.\n",
        "\n",
        "Thus, we stay with our choice of $128$ neurons per layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Taking a more drastic approach regarding network architecture, let's consider the following: With MNIST being an image dataset, why not just use a CNN?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 509,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_neurons, dropout_rate):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.LazyConv2d(32, 3),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(),\n",
        "            nn.LazyConv2d(32, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.LazyLinear(hidden_neurons),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.LazyLinear(classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 511,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Acc: Train 91.15% Test 97.69% | Avg Loss: 0.2853 Min Loss: 0.0153\n",
            "Epoch 2 | Acc: Train 97.18% Test 98.33% | Avg Loss: 0.0922 Min Loss: 0.0056\n",
            "Epoch 3 | Acc: Train 98.00% Test 98.54% | Avg Loss: 0.0663 Min Loss: 0.0032\n",
            "Epoch 4 | Acc: Train 98.26% Test 98.71% | Avg Loss: 0.0554 Min Loss: 0.0011\n",
            "Epoch 5 | Acc: Train 98.54% Test 98.90% | Avg Loss: 0.0456 Min Loss: 0.0007\n",
            "Epoch 6 | Acc: Train 98.80% Test 98.88% | Avg Loss: 0.0384 Min Loss: 0.0009\n",
            "Epoch 7 | Acc: Train 98.94% Test 99.08% | Avg Loss: 0.0330 Min Loss: 0.0003\n",
            "Epoch 8 | Acc: Train 98.98% Test 99.05% | Avg Loss: 0.0310 Min Loss: 0.0003\n",
            "Epoch 9 | Acc: Train 99.14% Test 98.99% | Avg Loss: 0.0267 Min Loss: 0.0003\n",
            "Epoch 10 | Acc: Train 99.21% Test 98.98% | Avg Loss: 0.0234 Min Loss: 0.0002\n",
            "Epoch 11 | Acc: Train 99.20% Test 99.18% | Avg Loss: 0.0233 Min Loss: 0.0001\n",
            "Epoch 12 | Acc: Train 99.32% Test 99.05% | Avg Loss: 0.0194 Min Loss: 0.0001\n",
            "Epoch 13 | Acc: Train 99.43% Test 99.04% | Avg Loss: 0.0162 Min Loss: 0.0000\n",
            "Epoch 14 | Acc: Train 99.40% Test 98.98% | Avg Loss: 0.0171 Min Loss: 0.0001\n",
            "Epoch 15 | Acc: Train 99.41% Test 99.11% | Avg Loss: 0.0156 Min Loss: 0.0000\n",
            "Epoch 16 | Acc: Train 99.45% Test 98.95% | Avg Loss: 0.0149 Min Loss: 0.0000\n",
            "Epoch 17 | Acc: Train 99.46% Test 99.01% | Avg Loss: 0.0143 Min Loss: 0.0000\n",
            "Epoch 18 | Acc: Train 99.55% Test 98.98% | Avg Loss: 0.0121 Min Loss: 0.0000\n",
            "Epoch 19 | Acc: Train 99.51% Test 99.09% | Avg Loss: 0.0119 Min Loss: 0.0000\n",
            "Epoch 20 | Acc: Train 99.60% Test 99.00% | Avg Loss: 0.0102 Min Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "cnn = ConvNet(128, 0.5)\n",
        "optimizer = optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9)\n",
        "train(20, cnn, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we expected, even just after *two* epochs and with *no* hyperparameter optimization, the CNN has proved to be better than the MLP.\n",
        "\n",
        "This suggests that the reason why we weren't able to improve the accuracy of the MLP further than $98\\%$ was because of *bias*; the MLP just wasn't the right tool and couldn't fit the data better than that.\n",
        "\n",
        "We could add more dropout layers to the CNN to try to further increase performance, possibly one right before the fully connected part of the network, but we have to be aware of the fact that there's a noise factor that we cannot control, so accuracy will definitely not go much higher that the $99\\%$ we achieved with the CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is not required but I wanted to play a bit with matplotlib and how to display images alongside predictions, so I might as well hand it in with the rest of the work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 474,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 502,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 8 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rows = 2\n",
        "cols = 4\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n",
        "\n",
        "for i, (instance, label) in enumerate(DataLoader(test_set, 1)):\n",
        "    if i >= rows * cols:\n",
        "        break\n",
        "\n",
        "    ax = axes[i // cols, i % cols]\n",
        "    ax.imshow(test_set.data[i], cmap=\"gray\")\n",
        "    ax.set_title(f\"Label: {label.item()} Predicted: {model(instance).argmax(1).item()}\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
